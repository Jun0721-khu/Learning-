{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VscTMSVedYK3"
      },
      "source": [
        "ResNet18 모델 정의 및 인스턴스 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vFvRnaydV83"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "import os\r\n",
        "\r\n",
        "#Basic Block 정의\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "  def __init__(self, in_planes, planes, stride = 1):\r\n",
        "    super(BasicBlock, self).__init__()\r\n",
        "\r\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1,  bias = False)\r\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "\r\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\r\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "    #nn.Sequential은 다른 Module들을 포함하는 Module로, 그 Module들을 순차적으로 적용하여 출력을 생성한다.\r\n",
        "    #nn.Sequential(x)이면 x가 그대로 들어간다.\r\n",
        "    self.shortcut = nn.Sequential()\r\n",
        "    if stride != 1:\r\n",
        "      self.shortcut = nn.Sequential(\r\n",
        "          nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\r\n",
        "          nn.BatchNorm2d(planes)\r\n",
        "      )\r\n",
        "  def forward(self, x):\r\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "    out = self.bn2(self.conv2(out))\r\n",
        "    out += self.shortcut(x)\r\n",
        "    out = F.relu(out)\r\n",
        "    return out\r\n",
        "#ResNet 정의\r\n",
        "class ResNet(nn.Module):\r\n",
        "  def __init__(self, block, num_block, num_classes = 10):\r\n",
        "    super(ResNet, self).__init__()\r\n",
        "    self.in_planes = 64\r\n",
        "    #64개의 3x3 필터를 사용\r\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1, bias = False)\r\n",
        "    self.bn1 = nn.BatchNorm2d(64)\r\n",
        "    self.layer1 = self._make_layer(block, 64, num_block[0], stride = 1)\r\n",
        "    self.layer2 = self._make_layer(block, 128, num_block[1], stride = 2)\r\n",
        "    self.layer3 = self._make_layer(block, 256, num_block[2], stride = 2)\r\n",
        "    self.layer4 = self._make_layer(block, 512, num_block[3], stride = 2)\r\n",
        "    self.linear = nn.Linear(512, num_classes)\r\n",
        "  def _make_layer(self, block, planes, num_block, stride):\r\n",
        "    strides = [stride] + [1]*(num_block-1)\r\n",
        "    layers = []\r\n",
        "    for stride in strides:\r\n",
        "      layers.append(block(self.in_planes, planes, stride))\r\n",
        "      self.in_planes = planes    \r\n",
        "    return nn.Sequential(*layers)\r\n",
        "  def forward(self, x):\r\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "    out = self.layer1(out)\r\n",
        "    out = self.layer2(out)\r\n",
        "    out = self.layer3(out)\r\n",
        "    out = self.layer4(out)\r\n",
        "    out = F.avg_pool2d(out, 4)\r\n",
        "    out = out.view(out.size(0), -1)\r\n",
        "    out = self.linear(out)\r\n",
        "    return out\r\n",
        "\r\n",
        "#ResNey18함수 정의\r\n",
        "def ResNet18():\r\n",
        "  return ResNet(BasicBlock, [2, 2, 2, 2])\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU6xwEbgiKMG"
      },
      "source": [
        "데이터셋 다운로드 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlC1ZWiriEmx",
        "outputId": "aed32012-67cd-41ab-9bee-73ffaf6e6ac7"
      },
      "source": [
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "transform_train = transforms.Compose([\r\n",
        "                                      transforms.RandomCrop(32, padding =4),\r\n",
        "                                      transforms.RandomHorizontalFlip(),\r\n",
        "                                      transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "transform_test = transforms.Compose([\r\n",
        "                                     transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\r\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle = True, num_workers = 4)\r\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False, num_workers = 4)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdfPO8RBjj1p"
      },
      "source": [
        "환경 설정 및 학습 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYv2qMdbjc4_"
      },
      "source": [
        "device = 'cuda'\r\n",
        "\r\n",
        "net = ResNet18()\r\n",
        "net = net.to(device)\r\n",
        "net = torch.nn.DataParallel(net)\r\n",
        "cudnn.benchmark = True\r\n",
        "\r\n",
        "learning_rate = 0.1\r\n",
        "file_name = 'resnet18_cifar10.pt'\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 0.0002)\r\n",
        "\r\n",
        "def train(epoch):\r\n",
        "  print('\\n [Train Epoch : %d]' % epoch)\r\n",
        "\r\n",
        "  net.train()\r\n",
        "  train_loss = 0\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "\r\n",
        "  for batch_idx, (inputs, targets) in enumerate(train_loader):\r\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    benign_outputs = net(inputs)\r\n",
        "    loss = criterion(benign_outputs, targets)\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "    train_loss += loss.item()\r\n",
        "\r\n",
        "    _, predicted = benign_outputs.max(1)\r\n",
        "\r\n",
        "    total += targets.size(0)\r\n",
        "    correct += predicted.eq(targets).sum().item()\r\n",
        "\r\n",
        "    if batch_idx % 100 == 0:\r\n",
        "      print('\\n Current batch:', str(batch_idx))\r\n",
        "      print('Current benign train accuracy: ', str(predicted.eq(targets).sum().item()/targets.size(0)))\r\n",
        "      print('Current benign train loss : ', loss.item())\r\n",
        "  print('\\n Total benign train accuracy : ', 100.*correct/total)\r\n",
        "  print('Total benign train loss : ', train_loss)\r\n",
        "\r\n",
        "def test(epoch):\r\n",
        "  print('\\n [Test Epoch : %d]' %epoch)\r\n",
        "  net.eval()\r\n",
        "  loss = 0\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "\r\n",
        "  for batch_idx, (inputs, targets) in enumerate(test_loader):\r\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\r\n",
        "    total += targets.size(0)\r\n",
        "\r\n",
        "    outputs = net(inputs)\r\n",
        "    loss += criterion(outputs, targets).item()\r\n",
        "\r\n",
        "    _, predicted = outputs.max(1)\r\n",
        "    correct += predicted.eq(targets).sum().item()\r\n",
        "  \r\n",
        "  print('\\n Test accuracy:', 100. * correct / total)\r\n",
        "  print('Test average loss:', loss/total)\r\n",
        "\r\n",
        "  state = {'net':net.state_dict()}\r\n",
        "\r\n",
        "  if not os.path.isdir('checkpoint'):\r\n",
        "    os.mkdir('checkpoint')\r\n",
        "  torch.save(state, './checkpoint/' + file_name)\r\n",
        "  print('Model Saved!')\r\n",
        "\r\n",
        "def adjust_learning_rate(optimizer, epoch):\r\n",
        "  lr = learning_rate\r\n",
        "  if epoch >= 100:\r\n",
        "    lr /= 10\r\n",
        "  if epoch >= 150:\r\n",
        "    lr /= 10\r\n",
        "  for param_group in optimizer.param_groups:\r\n",
        "    param_group['lr'] = lr\r\n",
        "\r\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aVRP3UijsKy",
        "outputId": "eea2f96c-d641-4232-c55c-575ac3b639af"
      },
      "source": [
        "for epoch in range(0, 20):\r\n",
        "  adjust_learning_rate(optimizer, epoch)\r\n",
        "  train(epoch)\r\n",
        "  test(epoch)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " [Train Epoch : 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.125\n",
            "Current benign train loss :  2.3161888122558594\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.2421875\n",
            "Current benign train loss :  1.8951737880706787\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.3203125\n",
            "Current benign train loss :  1.8026175498962402\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.3515625\n",
            "Current benign train loss :  1.7564424276351929\n",
            "\n",
            " Total benign train accuracy :  31.058\n",
            "Total benign train loss :  744.8381662368774\n",
            "\n",
            " [Test Epoch : 0]\n",
            "\n",
            " Test accuracy: 36.88\n",
            "Test average loss: 0.017830971002578737\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 1]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.4765625\n",
            "Current benign train loss :  1.3857836723327637\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.4453125\n",
            "Current benign train loss :  1.4489315748214722\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.46875\n",
            "Current benign train loss :  1.3605846166610718\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.5\n",
            "Current benign train loss :  1.35646390914917\n",
            "\n",
            " Total benign train accuracy :  47.078\n",
            "Total benign train loss :  560.1944550275803\n",
            "\n",
            " [Test Epoch : 1]\n",
            "\n",
            " Test accuracy: 50.03\n",
            "Test average loss: 0.014267891061306\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 2]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.5625\n",
            "Current benign train loss :  1.1846879720687866\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.5546875\n",
            "Current benign train loss :  1.2663403749465942\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.5625\n",
            "Current benign train loss :  1.1727375984191895\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.5703125\n",
            "Current benign train loss :  1.1260793209075928\n",
            "\n",
            " Total benign train accuracy :  57.2\n",
            "Total benign train loss :  463.97747671604156\n",
            "\n",
            " [Test Epoch : 2]\n",
            "\n",
            " Test accuracy: 58.16\n",
            "Test average loss: 0.011528700280189513\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 3]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.703125\n",
            "Current benign train loss :  1.0654528141021729\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.6875\n",
            "Current benign train loss :  0.9605581760406494\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.6328125\n",
            "Current benign train loss :  1.0742906332015991\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.6953125\n",
            "Current benign train loss :  0.8442017436027527\n",
            "\n",
            " Total benign train accuracy :  65.248\n",
            "Total benign train loss :  382.8808356523514\n",
            "\n",
            " [Test Epoch : 3]\n",
            "\n",
            " Test accuracy: 56.26\n",
            "Test average loss: 0.013868213844299317\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 4]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.671875\n",
            "Current benign train loss :  0.8177471160888672\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.6796875\n",
            "Current benign train loss :  0.8968859910964966\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.6953125\n",
            "Current benign train loss :  0.8064510822296143\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.6640625\n",
            "Current benign train loss :  0.9500656127929688\n",
            "\n",
            " Total benign train accuracy :  70.428\n",
            "Total benign train loss :  329.2860242128372\n",
            "\n",
            " [Test Epoch : 4]\n",
            "\n",
            " Test accuracy: 72.23\n",
            "Test average loss: 0.008106414270401001\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 5]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.734375\n",
            "Current benign train loss :  0.7607038021087646\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.7578125\n",
            "Current benign train loss :  0.690897524356842\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.765625\n",
            "Current benign train loss :  0.7123437523841858\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.75\n",
            "Current benign train loss :  0.7819677591323853\n",
            "\n",
            " Total benign train accuracy :  74.484\n",
            "Total benign train loss :  284.34872111678123\n",
            "\n",
            " [Test Epoch : 5]\n",
            "\n",
            " Test accuracy: 70.03\n",
            "Test average loss: 0.009014260733127595\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 6]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.765625\n",
            "Current benign train loss :  0.6349879503250122\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.71875\n",
            "Current benign train loss :  0.8312934041023254\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.8203125\n",
            "Current benign train loss :  0.6108572483062744\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.765625\n",
            "Current benign train loss :  0.610205352306366\n",
            "\n",
            " Total benign train accuracy :  77.618\n",
            "Total benign train loss :  249.01745972037315\n",
            "\n",
            " [Test Epoch : 6]\n",
            "\n",
            " Test accuracy: 70.48\n",
            "Test average loss: 0.008998942428827286\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 7]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.7109375\n",
            "Current benign train loss :  0.8213023543357849\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.8359375\n",
            "Current benign train loss :  0.5272930860519409\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.7890625\n",
            "Current benign train loss :  0.6011489629745483\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.78125\n",
            "Current benign train loss :  0.6797612905502319\n",
            "\n",
            " Total benign train accuracy :  80.068\n",
            "Total benign train loss :  225.13974875211716\n",
            "\n",
            " [Test Epoch : 7]\n",
            "\n",
            " Test accuracy: 73.38\n",
            "Test average loss: 0.00863772137761116\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 8]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.8203125\n",
            "Current benign train loss :  0.5295745134353638\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.84375\n",
            "Current benign train loss :  0.5394704937934875\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.765625\n",
            "Current benign train loss :  0.6240430474281311\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.8359375\n",
            "Current benign train loss :  0.48281651735305786\n",
            "\n",
            " Total benign train accuracy :  81.942\n",
            "Total benign train loss :  203.9027078449726\n",
            "\n",
            " [Test Epoch : 8]\n",
            "\n",
            " Test accuracy: 79.84\n",
            "Test average loss: 0.005782892942428589\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 9]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.8125\n",
            "Current benign train loss :  0.5053553581237793\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.796875\n",
            "Current benign train loss :  0.6431808471679688\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.828125\n",
            "Current benign train loss :  0.5648431181907654\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.7578125\n",
            "Current benign train loss :  0.7938782572746277\n",
            "\n",
            " Total benign train accuracy :  83.64\n",
            "Total benign train loss :  185.69472390413284\n",
            "\n",
            " [Test Epoch : 9]\n",
            "\n",
            " Test accuracy: 80.06\n",
            "Test average loss: 0.005916924419999123\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 10]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.78125\n",
            "Current benign train loss :  0.48462432622909546\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.8125\n",
            "Current benign train loss :  0.4846685230731964\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.84375\n",
            "Current benign train loss :  0.5164790749549866\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.8359375\n",
            "Current benign train loss :  0.45128047466278076\n",
            "\n",
            " Total benign train accuracy :  84.708\n",
            "Total benign train loss :  172.27137504518032\n",
            "\n",
            " [Test Epoch : 10]\n",
            "\n",
            " Test accuracy: 74.43\n",
            "Test average loss: 0.007985164043307305\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 11]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.84375\n",
            "Current benign train loss :  0.5242195129394531\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.796875\n",
            "Current benign train loss :  0.5568702816963196\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.859375\n",
            "Current benign train loss :  0.4944274127483368\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.828125\n",
            "Current benign train loss :  0.46490469574928284\n",
            "\n",
            " Total benign train accuracy :  85.832\n",
            "Total benign train loss :  160.67987562716007\n",
            "\n",
            " [Test Epoch : 11]\n",
            "\n",
            " Test accuracy: 84.5\n",
            "Test average loss: 0.004682307681441307\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 12]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.875\n",
            "Current benign train loss :  0.33578261733055115\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.859375\n",
            "Current benign train loss :  0.48788461089134216\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.9140625\n",
            "Current benign train loss :  0.3045087456703186\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.8828125\n",
            "Current benign train loss :  0.32520192861557007\n",
            "\n",
            " Total benign train accuracy :  86.648\n",
            "Total benign train loss :  150.2691405415535\n",
            "\n",
            " [Test Epoch : 12]\n",
            "\n",
            " Test accuracy: 80.07\n",
            "Test average loss: 0.006049911612272262\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 13]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.890625\n",
            "Current benign train loss :  0.2881719768047333\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.828125\n",
            "Current benign train loss :  0.408025860786438\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.90625\n",
            "Current benign train loss :  0.3305472433567047\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.8984375\n",
            "Current benign train loss :  0.3241192698478699\n",
            "\n",
            " Total benign train accuracy :  87.4\n",
            "Total benign train loss :  142.611530482769\n",
            "\n",
            " [Test Epoch : 13]\n",
            "\n",
            " Test accuracy: 82.73\n",
            "Test average loss: 0.0050771922528743746\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 14]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.875\n",
            "Current benign train loss :  0.39457204937934875\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.890625\n",
            "Current benign train loss :  0.2763534188270569\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.875\n",
            "Current benign train loss :  0.43694815039634705\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.859375\n",
            "Current benign train loss :  0.4380088150501251\n",
            "\n",
            " Total benign train accuracy :  87.812\n",
            "Total benign train loss :  136.89719504117966\n",
            "\n",
            " [Test Epoch : 14]\n",
            "\n",
            " Test accuracy: 83.54\n",
            "Test average loss: 0.004901562325656414\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 15]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.8671875\n",
            "Current benign train loss :  0.3532952070236206\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.8046875\n",
            "Current benign train loss :  0.5835343599319458\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.875\n",
            "Current benign train loss :  0.3343362510204315\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.9140625\n",
            "Current benign train loss :  0.28568682074546814\n",
            "\n",
            " Total benign train accuracy :  88.834\n",
            "Total benign train loss :  127.0646416246891\n",
            "\n",
            " [Test Epoch : 15]\n",
            "\n",
            " Test accuracy: 83.1\n",
            "Test average loss: 0.004841890773177147\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 16]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.875\n",
            "Current benign train loss :  0.33118364214897156\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.9375\n",
            "Current benign train loss :  0.22294765710830688\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.8671875\n",
            "Current benign train loss :  0.33762550354003906\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.8984375\n",
            "Current benign train loss :  0.2776053249835968\n",
            "\n",
            " Total benign train accuracy :  88.804\n",
            "Total benign train loss :  126.15311662852764\n",
            "\n",
            " [Test Epoch : 16]\n",
            "\n",
            " Test accuracy: 76.32\n",
            "Test average loss: 0.007328951755166054\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 17]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.9296875\n",
            "Current benign train loss :  0.2165745198726654\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.9296875\n",
            "Current benign train loss :  0.2137482911348343\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.890625\n",
            "Current benign train loss :  0.2696615159511566\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.8671875\n",
            "Current benign train loss :  0.36485639214515686\n",
            "\n",
            " Total benign train accuracy :  89.522\n",
            "Total benign train loss :  118.98771345615387\n",
            "\n",
            " [Test Epoch : 17]\n",
            "\n",
            " Test accuracy: 86.08\n",
            "Test average loss: 0.004227927543222904\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 18]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.9296875\n",
            "Current benign train loss :  0.22813430428504944\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.90625\n",
            "Current benign train loss :  0.28062498569488525\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.890625\n",
            "Current benign train loss :  0.3308132290840149\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.875\n",
            "Current benign train loss :  0.28183332085609436\n",
            "\n",
            " Total benign train accuracy :  89.892\n",
            "Total benign train loss :  115.35879790782928\n",
            "\n",
            " [Test Epoch : 18]\n",
            "\n",
            " Test accuracy: 85.88\n",
            "Test average loss: 0.0041518665999174115\n",
            "Model Saved!\n",
            "\n",
            " [Train Epoch : 19]\n",
            "\n",
            " Current batch: 0\n",
            "Current benign train accuracy:  0.921875\n",
            "Current benign train loss :  0.22716198861598969\n",
            "\n",
            " Current batch: 100\n",
            "Current benign train accuracy:  0.8828125\n",
            "Current benign train loss :  0.3668651282787323\n",
            "\n",
            " Current batch: 200\n",
            "Current benign train accuracy:  0.90625\n",
            "Current benign train loss :  0.36972829699516296\n",
            "\n",
            " Current batch: 300\n",
            "Current benign train accuracy:  0.84375\n",
            "Current benign train loss :  0.4891888201236725\n",
            "\n",
            " Total benign train accuracy :  90.144\n",
            "Total benign train loss :  111.60110919177532\n",
            "\n",
            " [Test Epoch : 19]\n",
            "\n",
            " Test accuracy: 84.92\n",
            "Test average loss: 0.004604103247821331\n",
            "Model Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLMvPSEFn3Bw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}